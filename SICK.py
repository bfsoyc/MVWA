'''
Copyright @2018 PKU Calis.
All rights reserved.

The class SICKData encapsules all functions operated on SICK dataset.
Use the function loadData(dataPath) to get an instance of class SICKData and set the parameter dataPath to the path to the file token.txt generated by the script dataTransformSICK.py.
'''

import random
import math
import numpy as np

class SICKData():
	# static variable, shared by all object of this class	
	rawDataA = []
	slenA = []		# sentence length
	rawDataB = []
	slenB = []
	rawLabel = []	
	trainSet = []
	validSet = []
	testSet = []	
	maxLen = 0

	def __init__(self):
		self.nextIdx = 0
		self.epoch = 0
		self.tokenMap = {}

	def getNextBatch(self, batchSize):
		n = len(self.trainSet)
		if (batchSize > n):
			raise Exception("batchSize should not bigger than total number of training samples")
		elif (self.nextIdx + batchSize > n):
			retA = [self.rawDataA[i] for i in self.trainSet[self.nextIdx:]] + [self.rawDataA[i] for i in self.trainSet[:(self.nextIdx+batchSize)%n]]
			retB = [self.rawDataB[i] for i in self.trainSet[self.nextIdx:]] + [self.rawDataB[i] for i in self.trainSet[:(self.nextIdx+batchSize)%n]]
			label = [self.rawLabel[i] for i in self.trainSet[self.nextIdx:]] + [self.rawLabel[i] for i in self.trainSet[:(self.nextIdx+batchSize)%n]]		
			lenA = [self.slenA[i] for i in self.trainSet[self.nextIdx:]] + [self.slenA[i] for i in self.trainSet[:(self.nextIdx+batchSize)%n]]	
			lenB = [self.slenB[i] for i in self.trainSet[self.nextIdx:]] + [self.slenB[i] for i in self.trainSet[:(self.nextIdx+batchSize)%n]]
			self.epoch = self.epoch + 1
			if (self.epoch % 2 == 0):
				self.shuffleTrainSet()	# shuffle the training set every two epoch	
		else:
			retA = [self.rawDataA[i] for i in self.trainSet[self.nextIdx:self.nextIdx+batchSize]] 
			retB = [self.rawDataB[i] for i in self.trainSet[self.nextIdx:self.nextIdx+batchSize]] 
			label = [self.rawLabel[i] for i in self.trainSet[self.nextIdx:self.nextIdx+batchSize]]
			lenA = [self.slenA[i] for i in self.trainSet[self.nextIdx:self.nextIdx+batchSize]] 
			lenB = [self.slenB[i] for i in self.trainSet[self.nextIdx:self.nextIdx+batchSize]] 
		self.nextIdx = (self.nextIdx + batchSize) % n
		return retA, retB, label, lenA, lenB
	
	def getValidSet(self):
		retA = [self.rawDataA[i] for i in self.validSet]
		retB = [self.rawDataB[i] for i in self.validSet]
		label = [self.rawLabel[i] for i in self.validSet]
		lenA = [self.slenA[i] for i in self.validSet]
		lenB = [self.slenB[i] for i in self.validSet]
		return retA, retB, label, lenA, lenB, self.validSet

	def getTestSet(self):
		retA = [self.rawDataA[i] for i in self.testSet]
		retB = [self.rawDataB[i] for i in self.testSet]
		label = [self.rawLabel[i] for i in self.testSet]
		lenA = [self.slenA[i] for i in self.testSet]
		lenB = [self.slenB[i] for i in self.testSet]
		return retA, retB, label, lenA, lenB, self.testSet

	def shuffleTrainSet(self):
		random.shuffle(self.trainSet)
		self.nextIdx = 0
		print 'training set get shuffled@@@@@@@@@@@@@@@@@@@@@@@@@@@@epoch:\t %d' % self.epoch

	def printInfo(self):
		print 'train set:\t', len( self.trainSet )
		print 'valid set:\t', len( self.validSet )
		print 'test set:\t' , len( self.testSet )
		# statistic
		cnt = [0 for i in range(self.maxLen+1)]
		for l in self.slenA:
			cnt[l] = cnt[l]+1
		for l in self.slenB:
			cnt[l] = cnt[l]+1

		n = len( self.slenA )*2
		if n != np.sum(cnt):
			print 'n = %d ,  total count = %d, there is some bad sentences' % (n, np.sum(cnt) )

		# we quantize the float score into integer ranged from 2 to 9
		score_cnt = [0 for i in range( 12 )]
		for s in self.rawLabel:
			idx = min(9, int(np.floor(s * 2)))
			score_cnt[idx] = score_cnt[idx] + 1

		print '======================SICK statistic====================='
		print 'length\tcount\tpercentage'		
		for i in range(1,self.maxLen+1):
			print '%d\t%d\t%.2f%%' %(i, cnt[i], 100.0 * cnt[i] / n)

		print 'score_range\tcount\tpercentage'		
		for i in range(2, 10):
			print '[%.1f,%.1f%s\t%d\t%.2f%%' % (i / 2.0, i / 2.0 + 0.5, ']' if i==9 else ')', score_cnt[i], 100.0 * score_cnt[i] / n * 2)
		print '=========================================================\n'

	def loadVocb(self, path):
		file_to_read = open(path, 'r')
		for line in file_to_read:
			word, word_id = line.split('\t')
			self.tokenMap[int(word_id)] = word
		file_to_read.close()

	def displaySent(self, sent, lens = None):
		if lens == None:
			lens = range(len(sent))
		s = []
		for token_id, itr in zip( sent, range(lens) ):
			if self.tokenMap.has_key( token_id ):
				s.append( self.tokenMap[token_id] )
			else:
				s.append( '<oov>' )
		print ' '.join( s )
		return s
				

def loadData(dataPath, vocbSize = 2):
	data = SICKData()	# a class to capsule all datas

	inFile = open(dataPath, "r")
	maxLen = 0	# maximum length of sentences
	for line in inFile:
		items = line.split('\t')
		data.rawLabel.append(float(items[2]))
		sentA = []
		for token in items[0].split(' '):
			sentA.append(int(token))
		sentB = []
		for token in items[1].split(' '):
			sentB.append(int(token))
		data.rawDataA.append(sentA)
		data.slenA.append(len(sentA))
		data.rawDataB.append(sentB)
		data.slenB.append(len(sentB))
		maxLen = max(max(maxLen, len(sentA)), len(sentB))

	# adjust each sentence to same length by appeding end symbol to the end
	# token 'vocbSize-1' represents for the end symbol of sequences, whose word vector is vector of zeros. 
	data.rawDataA = [sent + [vocbSize-1]*(maxLen-len(sent)) for sent in data.rawDataA]
	data.rawDataB = [sent + [vocbSize-1]*(maxLen-len(sent)) for sent in data.rawDataB]
	data.maxLen = maxLen

	samplesCnt = len(data.rawLabel)
	rk = range( samplesCnt )
	random.seed( 5233 ) # fixed random seed 520
	random.shuffle( rk )
	
	# split dataset
	tr = 4500 # around 9/20 * samplesCnt
	va = 500
	#ts = 4927
	data.trainSet = rk[0:tr]
	data.validSet = rk[tr:tr+va]
	data.testSet = rk[tr+va:]
	
	data.printInfo()
	return data

